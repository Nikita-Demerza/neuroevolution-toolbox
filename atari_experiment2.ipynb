{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"iV7GFD8QRQVe"},"outputs":[],"source":["#!pip3 install \"gym[atari]\"\n","import gym\n","import sys\n","from PIL import Image, ImageDraw\n","import numpy as np\n","import pandas as pd\n","import neural_tape_controller\n","#Положительные числа - положительные награды.\n","import tasks \n","import optimize\n","import pickle5 as pickle\n","import torch"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Lu9KS73QWPJH"},"outputs":[],"source":["# HIDE OUTPUT\n","#!wget http://www.atarimania.com/roms/Roms.rar \n","#!unrar x -o+ ./Roms.rar >./roms\n","#!python3 -m atari_py.import_roms ./ROMS >./roms"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"gK_0udONWWcN"},"outputs":[{"name":"stdout","output_type":"stream","text":["Action Space: Discrete(9)\n","Observation Space: Box(0, 255, (210, 160, 3), uint8)\n","Max Episode Steps: 27000\n","Nondeterministic: False\n","Reward Range: (-inf, inf)\n","Reward Threshold: None\n"]},{"name":"stderr","output_type":"stream","text":["A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n","[Powered by Stella]\n"]}],"source":["def query_environment(name):\n","    env = gym.make(name)\n","    spec = gym.spec(name)\n","    print(f\"Action Space: {env.action_space}\")\n","    print(f\"Observation Space: {env.observation_space}\")\n","    print(f\"Max Episode Steps: {spec.max_episode_steps}\")\n","    print(f\"Nondeterministic: {spec.nondeterministic}\")\n","    print(f\"Reward Range: {env.reward_range}\")\n","    print(f\"Reward Threshold: {spec.reward_threshold}\")\n","query_environment(\"ALE/MsPacman-v5\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"yHqp2lahT3dG"},"outputs":[],"source":["def encode_simple(X):\n","  #как сделать простое кодирование? Ну давай разобьём картинку двумя разными сетками и измерим яркость\n","  #на входе одиночная картинка\n","  y_lst = []\n","  sz = np.shape(X)\n","  count_squares = 7\n","  for i in range(count_squares):\n","    for j in range(count_squares):\n","      x = X[int(i*sz[0]/count_squares):int((i+1)*sz[0]/count_squares), int(j*sz[1]/count_squares):int((j+1)*sz[1]/count_squares)]\n","      y_lst.append(np.nanmean(x))\n","\n","  count_squares = 3\n","  for i in range(count_squares):\n","    for j in range(count_squares):\n","      x = X[int(i*sz[0]/count_squares):int((i+1)*sz[0]/count_squares), int(j*sz[1]/count_squares):int((j+1)*sz[1]/count_squares)]\n","      y_lst.append(np.nanmean(x))\n","\n","  count_squares = 2\n","  for i in range(count_squares):\n","    for j in range(count_squares):\n","      x = X[int(i*sz[0]/count_squares):int((i+1)*sz[0]/count_squares), int(j*sz[1]/count_squares):int((j+1)*sz[1]/count_squares)]\n","      y_lst.append(np.nanmean(x))\n","  #размер: 62\n","  return np.array(y_lst)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"_hxFWNWoOsmJ"},"outputs":[],"source":["n_actions = 9\n","embed_size = 100800#это эмбеддинг картинки\n","nt = neural_tape_controller.nt_controller(input_size=embed_size,output_size=n_actions)\n","#try:\n","#    with open(root_dir+f'./genoms/best_genom_pacman.pkl', 'rb') as f:\n","#        genom = pickle.load(f)\n","#        genom = genom[-1]\n","#    print('loaded successfully')\n","#except Exception:\n","genom = nt.nn.disassemble_genom()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"bXF5TTLgIheU"},"outputs":[],"source":["def test_atary(genom, draw=False,game_name=\"ALE/MsPacman-v5\",seed=0,controller=None):\n","    env = gym.make(game_name)\n","    env.reset()\n","    n_actions = env.action_space.n\n","    state_dim = env.observation_space.shape#здесь картинка\n","    #print('n_actions',n_actions,'state_dim',state_dim)\n","    #1/0\n","    state_dim = embed_size#это эмбеддинг картинки\n","    if controller==None: controller = neural_tape_controller.nt_controller(tacts=1,genom=np.array(genom),input_size=state_dim,output_size=n_actions) \n","    out_tape = np.zeros(30)\n","    reward_sum = 0\n","    #seed=1\n","    #np.random.seed(seed)\n","    #env.seed(seed)\n","    while True:\n","        action = np.ravel(out_tape)\n","        action += np.random.rand(len(action))*np.std(action)*0.05#игра детерминистическая, иначе рандома не будет\n","        #print('action',int(np.argmax(action)),action)\n","        #исполнить env\n","        state, reward, done,_ = env.step(int(np.argmax(action)))\n","        t=pd.Timestamp.now()\n","        #state = encode_mobnet(np.array([state]))\n","        #state = encode_simple(state)\n","        reward_sum += reward\n","        #if np.shape(state)[0]>1:\n","        #    shp = np.shape(state)\n","        #    state = np.reshape(state,[1,shp[0]])\n","        if done:\n","            break\n","        out_tape = controller.act(torch.tensor(state),reward,done)\n","        if draw:\n","            globals()['video'].append(Image.fromarray(env.render(\"rgb_array\")))\n","    return reward_sum,controller"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"jn_DW2_xYhb_"},"outputs":[],"source":["def multy_test(genom,draw=False):\n","  if draw:\n","    globals()['video'] = []\n","\n","  game_name = \"ALE/MsPacman-v5\"\n","  #один энвайронмент, разные сиды\n","  controller = neural_tape_controller.nt_controller(tacts=1,genom=np.array(genom),input_size=100800,output_size=n_actions) \n","  q_arr = []\n","  for i in range(3):\n","    q,controller = test_atary(genom, draw=draw,game_name=game_name,controller=controller)\n","    q_arr.append(q*(i+1))\n","  return np.sum(q_arr)/len(q_arr)#-0.000000001*np.sum(genom**2)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"2bNLh6kmFzfY"},"outputs":[{"name":"stdout","output_type":"stream","text":["q= 60.0\n","CPU times: user 4.75 s, sys: 31 ms, total: 4.79 s\n","Wall time: 932 ms\n"]}],"source":["%%time\n","q,_=test_atary(genom,game_name=\"ALE/MsPacman-v5\", draw=False)\n","print('q=',q)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"cGZxP_NhdC27"},"outputs":[{"name":"stdout","output_type":"stream","text":["q= 120.0\n","CPU times: user 13.6 s, sys: 62.8 ms, total: 13.7 s\n","Wall time: 2.63 s\n"]}],"source":["%%time\n","q=multy_test(genom)\n","print('q=',q)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Eja2m2P_ewzM"},"outputs":[{"name":"stdout","output_type":"stream","text":["q= 60.0\n","CPU times: user 5.08 s, sys: 2.83 ms, total: 5.08 s\n","Wall time: 991 ms\n"]}],"source":["%%time\n","q,_=test_atary(genom)\n","print('q=',q)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"oN_h1Rg_2fQX"},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-06-08 19:56:55.835909\n"]}],"source":["print(pd.Timestamp.now())"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","loaded successfully\n","history loaded successfully\n"]}],"source":["print(1)\n","opt = optimize.optimizer(multy_test, genom_size=len(genom),parallel_cores=1,init_file='genoms/genom2.pkl',history_file='history/history.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["try:\n","    with open('genoms/genom_pacman.pkl', 'rb') as f:\n","        opt.best_genoms = pickle.load(f)\n","    print('loaded successfully')\n","except Exception:\n","    pass"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"HzpNigFUTmIM"},"outputs":[{"name":"stdout","output_type":"stream","text":["opt# 0\n","random trial\n","scores for optimizers augmented tensor([-4.4831e+01,  1.0000e+10,  1.0000e+10,  1.0000e+10,  9.9491e-01,\n","         1.0000e+10,  1.0000e+10,  1.0000e+10,  1.0000e+10])\n","chosen gradient_wide_50 previous_result: nan per tacts: nan\n","score_new 293.3333333333333 score_prev 643.3333333333334 gained -350.00000000000006\n","but success with one derivative: score_new 293.3333333333333 score_prev 643.3333333333334 gained -350.00000000000006\n","undo\n","score_new 696.6666666666666 score_prev 643.3333333333334 gained 53.33333333333326\n","score_new 676.6666666666666 score_prev 696.6666666666666 gained -20.0\n","but success with one derivative: score_new 643.3333333333334 score_prev 696.6666666666666 gained -53.33333333333326\n","undo\n","score_new 466.6666666666667 score_prev 696.6666666666666 gained -229.99999999999994\n","but success with one derivative: score_new 633.3333333333334 score_prev 696.6666666666666 gained -63.33333333333326\n","undo\n","score_new 666.6666666666666 score_prev 696.6666666666666 gained -30.0\n","but success with one derivative: score_new 1126.6666666666667 score_prev 696.6666666666666 gained 430.0000000000001\n","result gradient_wide_50 previous_gain: nan per tacts: nan duration 0 days 00:02:37.554347\n","WRITTEN\n","opt# 1\n","scores for optimizers augmented tensor([-4.6445e+01,  4.8331e+02,  1.0000e+10,  1.0000e+10, -4.0000e-02,\n","         1.0000e+10,  1.0000e+10,  1.0000e+10,  1.0000e+10])\n","chosen rel_coord_default previous_result: nan per tacts: nan\n","score_new 1196.6666666666667 score_prev 460.0 gained 736.6666666666667\n","score_new 986.6666666666666 score_prev 1196.6666666666667 gained -210.0000000000001\n","undo\n","score_new 450.0 score_prev 1196.6666666666667 gained -746.6666666666667\n","undo\n","score_new 410.0 score_prev 1196.6666666666667 gained -786.6666666666667\n","undo\n","score_new 546.6666666666666 score_prev 1196.6666666666667 gained -650.0000000000001\n","undo\n","score_new 410.0 score_prev 1196.6666666666667 gained -786.6666666666667\n","undo\n","score_new 576.6666666666666 score_prev 1196.6666666666667 gained -620.0000000000001\n","undo\n","score_new 593.3333333333334 score_prev 1196.6666666666667 gained -603.3333333333334\n","undo\n","score_new 566.6666666666666 score_prev 1196.6666666666667 gained -630.0000000000001\n","undo\n","score_new 380.0 score_prev 1196.6666666666667 gained -816.6666666666667\n","undo\n","score_new 1150.0 score_prev 1196.6666666666667 gained -46.66666666666674\n","undo\n","score_new 816.6666666666666 score_prev 1196.6666666666667 gained -380.0000000000001\n","undo\n","score_new 786.6666666666666 score_prev 1196.6666666666667 gained -410.0000000000001\n","undo\n","score_new 566.6666666666666 score_prev 1196.6666666666667 gained -630.0000000000001\n","undo\n","score_new 916.6666666666666 score_prev 1196.6666666666667 gained -280.0000000000001\n","undo\n","score_new 400.0 score_prev 1196.6666666666667 gained -796.6666666666667\n","undo\n","score_new 566.6666666666666 score_prev 1196.6666666666667 gained -630.0000000000001\n","undo\n","score_new 1186.6666666666667 score_prev 1196.6666666666667 gained -10.0\n","undo\n","score_new 446.6666666666667 score_prev 1196.6666666666667 gained -750.0\n","undo\n","score_new 1890.0 score_prev 1196.6666666666667 gained 693.3333333333333\n","score_new 1116.6666666666667 score_prev 1890.0 gained -773.3333333333333\n","undo\n","score_new 886.6666666666666 score_prev 1890.0 gained -1003.3333333333334\n","undo\n","score_new 400.0 score_prev 1890.0 gained -1490.0\n","undo\n","score_new 1656.6666666666667 score_prev 1890.0 gained -233.33333333333326\n","undo\n","score_new 546.6666666666666 score_prev 1890.0 gained -1343.3333333333335\n","undo\n","result rel_coord_default previous_gain: nan per tacts: nan duration 0 days 00:02:10.954935\n","WRITTEN\n","opt# 2\n","scores for optimizers augmented tensor([-4.6445e+01,  4.8331e+02,  1.4300e+03,  1.0000e+10, -4.0000e-02,\n","         1.0000e+10,  1.0000e+10,  1.0000e+10,  1.0000e+10])\n","chosen evol_soft previous_result: nan per tacts: nan\n","iteration 0 y= tensor([1453.3334, 1376.6666, 1060.0000])\n","iteration 1 y= tensor([843.3333, 693.3333, 590.0000])\n","iteration 2 y= tensor([1560.0000, 1426.6666, 1426.6666])\n","iteration 3 y= tensor([1426.6666, 1426.6666, 1426.6666])\n","iteration 4 y= tensor([1426.6666, 1426.6666, 1426.6666])\n"]}],"source":["\n","opt.function(opt.best_genoms[-1])\n","\n","for i in range(1000):\n","    print('opt#',i)\n","    opt.optimize()\n","    with open('genoms/best_genom_pacman.pkl', 'wb') as f:\n","        pickle.dump(opt.best_genoms,f,protocol=pickle.HIGHEST_PROTOCOL)\n","        print('WRITTEN')"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"LBhHJSL-ctuu"},"outputs":[{"name":"stdout","output_type":"stream","text":["q= 366.6666666666667\n"]}],"source":["with open('genoms/genom2.pkl', 'rb') as f:\n","    genom = pickle.load(f)#[-1]\n","q=multy_test(genom,draw=True)\n","print('q=',q)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"rquJJEbVcfgz"},"outputs":[],"source":["video[0].save(\n","    './out_videos/seaquest_pacman.gif',\n","    save_all=True,\n","    append_images=video[1:], \n","    optimize=True,\n","    duration=100,\n","    loop=0\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NolxDC4bdi7r"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP1/6tnER+ipw9TdwDyZ+sz","collapsed_sections":[],"mount_file_id":"1LelKGSZ7B8o8qafqCX4oFBtzHByVJ9FI","name":"atari_experiment2.ipynb","private_outputs":true,"provenance":[]},"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
