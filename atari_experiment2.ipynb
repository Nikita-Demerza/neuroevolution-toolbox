{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"iV7GFD8QRQVe"},"outputs":[],"source":["#!pip3 install \"gym[atari]\"\n","import gym\n","import sys\n","from PIL import Image, ImageDraw\n","import numpy as np\n","import pandas as pd\n","import neural_tape_controller\n","#Положительные числа - положительные награды.\n","import tasks \n","import optimize\n","import pickle5 as pickle\n","import torch"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Lu9KS73QWPJH"},"outputs":[],"source":["# HIDE OUTPUT\n","#!wget http://www.atarimania.com/roms/Roms.rar \n","#!unrar x -o+ ./Roms.rar >./roms\n","#!python3 -m atari_py.import_roms ./ROMS >./roms"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"gK_0udONWWcN"},"outputs":[{"name":"stdout","output_type":"stream","text":["Action Space: Discrete(9)\n","Observation Space: Box(0, 255, (210, 160, 3), uint8)\n","Max Episode Steps: 27000\n","Nondeterministic: False\n","Reward Range: (-inf, inf)\n","Reward Threshold: None\n"]},{"name":"stderr","output_type":"stream","text":["A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n","[Powered by Stella]\n"]}],"source":["def query_environment(name):\n","    env = gym.make(name)\n","    spec = gym.spec(name)\n","    print(f\"Action Space: {env.action_space}\")\n","    print(f\"Observation Space: {env.observation_space}\")\n","    print(f\"Max Episode Steps: {spec.max_episode_steps}\")\n","    print(f\"Nondeterministic: {spec.nondeterministic}\")\n","    print(f\"Reward Range: {env.reward_range}\")\n","    print(f\"Reward Threshold: {spec.reward_threshold}\")\n","query_environment(\"ALE/MsPacman-v5\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"yHqp2lahT3dG"},"outputs":[],"source":["def encode_simple(X):\n","  #как сделать простое кодирование? Ну давай разобьём картинку двумя разными сетками и измерим яркость\n","  #на входе одиночная картинка\n","  y_lst = []\n","  sz = np.shape(X)\n","  count_squares = 7\n","  for i in range(count_squares):\n","    for j in range(count_squares):\n","      x = X[int(i*sz[0]/count_squares):int((i+1)*sz[0]/count_squares), int(j*sz[1]/count_squares):int((j+1)*sz[1]/count_squares)]\n","      y_lst.append(np.nanmean(x))\n","\n","  count_squares = 3\n","  for i in range(count_squares):\n","    for j in range(count_squares):\n","      x = X[int(i*sz[0]/count_squares):int((i+1)*sz[0]/count_squares), int(j*sz[1]/count_squares):int((j+1)*sz[1]/count_squares)]\n","      y_lst.append(np.nanmean(x))\n","\n","  count_squares = 2\n","  for i in range(count_squares):\n","    for j in range(count_squares):\n","      x = X[int(i*sz[0]/count_squares):int((i+1)*sz[0]/count_squares), int(j*sz[1]/count_squares):int((j+1)*sz[1]/count_squares)]\n","      y_lst.append(np.nanmean(x))\n","  #размер: 62\n","  return np.array(y_lst)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"_hxFWNWoOsmJ"},"outputs":[],"source":["n_actions = 9\n","embed_size = 100800#это эмбеддинг картинки\n","nt = neural_tape_controller.nt_controller(input_size=embed_size,output_size=n_actions)\n","#try:\n","#    with open(root_dir+f'./genoms/best_genom_pacman.pkl', 'rb') as f:\n","#        genom = pickle.load(f)\n","#        genom = genom[-1]\n","#    print('loaded successfully')\n","#except Exception:\n","genom = nt.nn.disassemble_genom()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"bXF5TTLgIheU"},"outputs":[],"source":["def test_atary(genom, draw=False,game_name=\"ALE/MsPacman-v5\",seed=0,controller=None):\n","    env = gym.make(game_name)\n","    env.reset()\n","    n_actions = env.action_space.n\n","    state_dim = env.observation_space.shape#здесь картинка\n","    #print('n_actions',n_actions,'state_dim',state_dim)\n","    #1/0\n","    state_dim = embed_size#это эмбеддинг картинки\n","    if controller==None: controller = neural_tape_controller.nt_controller(tacts=1,genom=np.array(genom),input_size=state_dim,output_size=n_actions) \n","    out_tape = np.zeros(30)\n","    reward_sum = 0\n","    #seed=1\n","    #np.random.seed(seed)\n","    #env.seed(seed)\n","    while True:\n","        action = np.ravel(out_tape)\n","        action += np.random.rand(len(action))*np.std(action)*0.05#игра детерминистическая, иначе рандома не будет\n","        #print('action',int(np.argmax(action)),action)\n","        #исполнить env\n","        state, reward, done,_ = env.step(int(np.argmax(action)))\n","        t=pd.Timestamp.now()\n","        #state = encode_mobnet(np.array([state]))\n","        #state = encode_simple(state)\n","        reward_sum += reward\n","        #if np.shape(state)[0]>1:\n","        #    shp = np.shape(state)\n","        #    state = np.reshape(state,[1,shp[0]])\n","        if done:\n","            break\n","        out_tape = controller.act(torch.tensor(state),reward,done)\n","        if draw:\n","            globals()['video'].append(Image.fromarray(env.render(\"rgb_array\")))\n","    return reward_sum,controller"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"jn_DW2_xYhb_"},"outputs":[],"source":["def multy_test(genom,draw=False):\n","  if draw:\n","    globals()['video'] = []\n","\n","  game_name = \"ALE/MsPacman-v5\"\n","  #один энвайронмент, разные сиды\n","  controller = neural_tape_controller.nt_controller(tacts=1,genom=np.array(genom),input_size=100800,output_size=n_actions) \n","  q_arr = []\n","  for i in range(3):\n","    q,controller = test_atary(genom, draw=draw,game_name=game_name,controller=controller)\n","    q_arr.append(q*(i+1))\n","  return np.sum(q_arr)/len(q_arr)#-0.000000001*np.sum(genom**2)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"2bNLh6kmFzfY"},"outputs":[{"name":"stdout","output_type":"stream","text":["q= 160.0\n","CPU times: user 24.1 s, sys: 136 ms, total: 24.3 s\n","Wall time: 4.16 s\n"]}],"source":["%%time\n","q,_=test_atary(genom,game_name=\"ALE/MsPacman-v5\", draw=False)\n","print('q=',q)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cGZxP_NhdC27"},"outputs":[{"name":"stdout","output_type":"stream","text":["q= 663.3333333333334\n","CPU times: user 4min 32s, sys: 250 ms, total: 4min 32s\n","Wall time: 47.2 s\n"]}],"source":["%%time\n","q=multy_test(genom)\n","print('q=',q)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"Eja2m2P_ewzM"},"outputs":[{"name":"stdout","output_type":"stream","text":["q= 90.0\n","CPU times: user 54.9 s, sys: 24 ms, total: 54.9 s\n","Wall time: 9.31 s\n"]}],"source":["%%time\n","q,_=test_atary(genom)\n","print('q=',q)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"oN_h1Rg_2fQX"},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-06-05 17:57:35.150790\n"]}],"source":["print(pd.Timestamp.now())"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","history loaded successfully\n"]}],"source":["print(1)\n","opt = optimize.optimizer(multy_test, genom_size=len(genom),parallel_cores=1,init_file='genoms/genom2.pkl',history_file='history/history2.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["try:\n","    with open('genoms/genom_pacman.pkl', 'rb') as f:\n","        opt.best_genoms = pickle.load(f)\n","    print('loaded successfully')\n","except Exception:\n","    pass"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"HzpNigFUTmIM"},"outputs":[{"name":"stdout","output_type":"stream","text":["opt# 0\n","scores for optimizers augmented [-8.00450000e+01  3.26644167e+02  1.01664167e+03  1.65200000e+00\n","  2.22666667e+00 -4.20000000e-02 -7.50000000e-02  6.66666667e-02\n","  1.00000000e+10]\n","chosen evol_narrow previous_result: nan per tacts: nan\n","iteration 0 y= [703.33333333 590.        ]\n","iteration 1 y= [1033.33333333  840.        ]\n","iteration 2 y= [1013.33333333  820.        ]\n","iteration 3 y= [750. 550.]\n","iteration 4 y= [626.66666667 623.33333333]\n","iteration 5 y= [696.66666667 603.33333333]\n","iteration 6 y= [690.         683.33333333]\n","iteration 7 y= [1283.33333333  696.66666667]\n","iteration 8 y= [623.33333333 570.        ]\n","iteration 9 y= [706.66666667 673.33333333]\n","iteration 10 y= [676.66666667 576.66666667]\n","iteration 11 y= [840.         813.33333333]\n","iteration 12 y= [810.         563.33333333]\n","iteration 13 y= [790. 730.]\n","iteration 14 y= [746.66666667 653.33333333]\n","iteration 15 y= [866.66666667 706.66666667]\n","iteration final y= [923.33333333 893.33333333]\n","result evol_narrow previous_gain: 220.0 per tacts: 136 duration 0 days 03:14:26.488954\n","WRITTEN\n","opt# 1\n","scores for optimizers augmented [-8.00450000e+01  3.26644167e+02  1.01664167e+03  1.65200000e+00\n","  2.22666667e+00 -4.20000000e-02 -7.50000000e-02  6.66666667e-02\n","  2.19932000e+02]\n","chosen rel_coord_default previous_result: 220.0 per tacts: 136\n","score_new 480.0 score_prev 463.3333333333333 gained 16.666666666666686\n","score_new 556.6666666666666 score_prev 480.0 gained 76.66666666666663\n","score_new 533.3333333333334 score_prev 556.6666666666666 gained -23.333333333333258\n","undo\n","score_new 446.6666666666667 score_prev 556.6666666666666 gained -109.99999999999994\n","undo\n","score_new 803.3333333333334 score_prev 556.6666666666666 gained 246.66666666666674\n","score_new 376.6666666666667 score_prev 803.3333333333334 gained -426.6666666666667\n","undo\n","score_new 813.3333333333334 score_prev 803.3333333333334 gained 10.0\n","score_new 430.0 score_prev 813.3333333333334 gained -383.33333333333337\n","undo\n","score_new 443.3333333333333 score_prev 813.3333333333334 gained -370.00000000000006\n","undo\n","score_new 710.0 score_prev 813.3333333333334 gained -103.33333333333337\n","undo\n","score_new 400.0 score_prev 813.3333333333334 gained -413.33333333333337\n","undo\n","score_new 866.6666666666666 score_prev 813.3333333333334 gained 53.33333333333326\n","score_new 503.3333333333333 score_prev 866.6666666666666 gained -363.3333333333333\n","undo\n","score_new 413.3333333333333 score_prev 866.6666666666666 gained -453.3333333333333\n","undo\n","score_new 526.6666666666666 score_prev 866.6666666666666 gained -340.0\n","undo\n","score_new 420.0 score_prev 866.6666666666666 gained -446.66666666666663\n","undo\n","score_new 433.3333333333333 score_prev 866.6666666666666 gained -433.3333333333333\n","undo\n","score_new 500.0 score_prev 866.6666666666666 gained -366.66666666666663\n","undo\n","score_new 446.6666666666667 score_prev 866.6666666666666 gained -419.99999999999994\n","undo\n","score_new 483.3333333333333 score_prev 866.6666666666666 gained -383.3333333333333\n","undo\n","score_new 443.3333333333333 score_prev 866.6666666666666 gained -423.3333333333333\n","undo\n","score_new 363.3333333333333 score_prev 866.6666666666666 gained -503.3333333333333\n","undo\n","score_new 456.6666666666667 score_prev 866.6666666666666 gained -409.99999999999994\n","undo\n","score_new 706.6666666666666 score_prev 866.6666666666666 gained -160.0\n","undo\n","score_new 1050.0 score_prev 866.6666666666666 gained 183.33333333333337\n","result rel_coord_default previous_gain: 220.0 per tacts: 136 duration 0 days 00:38:17.259100\n","WRITTEN\n","opt# 2\n","scores for optimizers augmented [-8.00450000e+01  3.26644167e+02  8.01641667e+02  1.65200000e+00\n","  2.22666667e+00 -4.20000000e-02 -7.50000000e-02  6.66666667e-02\n","  2.19932000e+02]\n","chosen rel_coord_default previous_result: 220.0 per tacts: 136\n","score_new 896.6666666666666 score_prev 436.6666666666667 gained 459.99999999999994\n","score_new 413.3333333333333 score_prev 896.6666666666666 gained -483.3333333333333\n","undo\n","score_new 1023.3333333333334 score_prev 896.6666666666666 gained 126.66666666666674\n","score_new 430.0 score_prev 1023.3333333333334 gained -593.3333333333334\n","undo\n","score_new 650.0 score_prev 1023.3333333333334 gained -373.33333333333337\n","undo\n","score_new 423.3333333333333 score_prev 1023.3333333333334 gained -600.0\n","undo\n","score_new 523.3333333333334 score_prev 1023.3333333333334 gained -500.0\n","undo\n","score_new 766.6666666666666 score_prev 1023.3333333333334 gained -256.66666666666674\n","undo\n","score_new 483.3333333333333 score_prev 1023.3333333333334 gained -540.0\n","undo\n","score_new 560.0 score_prev 1023.3333333333334 gained -463.33333333333337\n","undo\n","score_new 443.3333333333333 score_prev 1023.3333333333334 gained -580.0\n","undo\n","score_new 490.0 score_prev 1023.3333333333334 gained -533.3333333333334\n","undo\n","score_new 696.6666666666666 score_prev 1023.3333333333334 gained -326.66666666666674\n","undo\n","score_new 766.6666666666666 score_prev 1023.3333333333334 gained -256.66666666666674\n","undo\n","score_new 446.6666666666667 score_prev 1023.3333333333334 gained -576.6666666666667\n","undo\n","score_new 486.6666666666667 score_prev 1023.3333333333334 gained -536.6666666666667\n","undo\n","score_new 366.6666666666667 score_prev 1023.3333333333334 gained -656.6666666666667\n","undo\n","score_new 443.3333333333333 score_prev 1023.3333333333334 gained -580.0\n","undo\n","score_new 463.3333333333333 score_prev 1023.3333333333334 gained -560.0\n","undo\n","score_new 510.0 score_prev 1023.3333333333334 gained -513.3333333333334\n","undo\n","score_new 360.0 score_prev 1023.3333333333334 gained -663.3333333333334\n","undo\n","score_new 480.0 score_prev 1023.3333333333334 gained -543.3333333333334\n","undo\n","score_new 400.0 score_prev 1023.3333333333334 gained -623.3333333333334\n","undo\n","score_new 530.0 score_prev 1023.3333333333334 gained -493.33333333333337\n","undo\n","score_new 503.3333333333333 score_prev 1023.3333333333334 gained -520.0\n","undo\n","result rel_coord_default previous_gain: 220.0 per tacts: 136 duration 0 days 00:39:46.872997\n","WRITTEN\n","opt# 3\n","scores for optimizers augmented [-8.00450000e+01  3.26644167e+02  7.29975000e+02  1.65200000e+00\n","  2.22666667e+00 -4.20000000e-02 -7.50000000e-02  6.66666667e-02\n","  2.19932000e+02]\n","chosen rel_coord_default previous_result: 220.0 per tacts: 136\n","score_new 513.3333333333334 score_prev 493.3333333333333 gained 20.000000000000057\n","score_new 430.0 score_prev 513.3333333333334 gained -83.33333333333337\n","undo\n","score_new 586.6666666666666 score_prev 513.3333333333334 gained 73.33333333333326\n","score_new 410.0 score_prev 586.6666666666666 gained -176.66666666666663\n","undo\n","score_new 490.0 score_prev 586.6666666666666 gained -96.66666666666663\n","undo\n","score_new 450.0 score_prev 586.6666666666666 gained -136.66666666666663\n","undo\n","score_new 1150.0 score_prev 586.6666666666666 gained 563.3333333333334\n","score_new 1466.6666666666667 score_prev 1150.0 gained 316.66666666666674\n","score_new 446.6666666666667 score_prev 1466.6666666666667 gained -1020.0\n","undo\n","score_new 440.0 score_prev 1466.6666666666667 gained -1026.6666666666667\n","undo\n","score_new 376.6666666666667 score_prev 1466.6666666666667 gained -1090.0\n","undo\n","score_new 383.3333333333333 score_prev 1466.6666666666667 gained -1083.3333333333335\n","undo\n","score_new 496.6666666666667 score_prev 1466.6666666666667 gained -970.0\n","undo\n","score_new 360.0 score_prev 1466.6666666666667 gained -1106.6666666666667\n","undo\n","score_new 516.6666666666666 score_prev 1466.6666666666667 gained -950.0000000000001\n","undo\n","score_new 573.3333333333334 score_prev 1466.6666666666667 gained -893.3333333333334\n","undo\n","score_new 613.3333333333334 score_prev 1466.6666666666667 gained -853.3333333333334\n","undo\n","score_new 346.6666666666667 score_prev 1466.6666666666667 gained -1120.0\n","undo\n","score_new 1566.6666666666667 score_prev 1466.6666666666667 gained 100.0\n","score_new 316.6666666666667 score_prev 1566.6666666666667 gained -1250.0\n","undo\n","score_new 486.6666666666667 score_prev 1566.6666666666667 gained -1080.0\n","undo\n","score_new 453.3333333333333 score_prev 1566.6666666666667 gained -1113.3333333333335\n","undo\n","score_new 473.3333333333333 score_prev 1566.6666666666667 gained -1093.3333333333335\n","undo\n","score_new 443.3333333333333 score_prev 1566.6666666666667 gained -1123.3333333333335\n","undo\n","score_new 506.6666666666667 score_prev 1566.6666666666667 gained -1060.0\n","undo\n","result rel_coord_default previous_gain: 220.0 per tacts: 136 duration 0 days 00:39:45.777165\n","WRITTEN\n","opt# 4\n","scores for optimizers augmented [-8.00450000e+01  3.26644167e+02  8.15808333e+02  1.65200000e+00\n","  2.22666667e+00 -4.20000000e-02 -7.50000000e-02  6.66666667e-02\n","  2.19932000e+02]\n","chosen rel_coord_default previous_result: 220.0 per tacts: 136\n","score_new 1256.6666666666667 score_prev 670.0 gained 586.6666666666667\n","score_new 543.3333333333334 score_prev 1256.6666666666667 gained -713.3333333333334\n","undo\n","score_new 500.0 score_prev 1256.6666666666667 gained -756.6666666666667\n","undo\n","score_new 520.0 score_prev 1256.6666666666667 gained -736.6666666666667\n","undo\n","score_new 643.3333333333334 score_prev 1256.6666666666667 gained -613.3333333333334\n","undo\n","score_new 353.3333333333333 score_prev 1256.6666666666667 gained -903.3333333333335\n","undo\n","score_new 596.6666666666666 score_prev 1256.6666666666667 gained -660.0000000000001\n","undo\n","score_new 523.3333333333334 score_prev 1256.6666666666667 gained -733.3333333333334\n","undo\n","score_new 360.0 score_prev 1256.6666666666667 gained -896.6666666666667\n","undo\n","score_new 390.0 score_prev 1256.6666666666667 gained -866.6666666666667\n","undo\n","score_new 580.0 score_prev 1256.6666666666667 gained -676.6666666666667\n","undo\n","score_new 510.0 score_prev 1256.6666666666667 gained -746.6666666666667\n","undo\n","score_new 416.6666666666667 score_prev 1256.6666666666667 gained -840.0\n","undo\n","score_new 420.0 score_prev 1256.6666666666667 gained -836.6666666666667\n","undo\n","score_new 366.6666666666667 score_prev 1256.6666666666667 gained -890.0\n","undo\n","score_new 453.3333333333333 score_prev 1256.6666666666667 gained -803.3333333333335\n","undo\n","score_new 436.6666666666667 score_prev 1256.6666666666667 gained -820.0\n","undo\n","score_new 443.3333333333333 score_prev 1256.6666666666667 gained -813.3333333333335\n","undo\n","score_new 470.0 score_prev 1256.6666666666667 gained -786.6666666666667\n","undo\n","score_new 516.6666666666666 score_prev 1256.6666666666667 gained -740.0000000000001\n","undo\n","score_new 430.0 score_prev 1256.6666666666667 gained -826.6666666666667\n","undo\n","score_new 473.3333333333333 score_prev 1256.6666666666667 gained -783.3333333333335\n","undo\n","score_new 406.6666666666667 score_prev 1256.6666666666667 gained -850.0\n","undo\n","score_new 610.0 score_prev 1256.6666666666667 gained -646.6666666666667\n","undo\n","score_new 523.3333333333334 score_prev 1256.6666666666667 gained -733.3333333333334\n","undo\n","result rel_coord_default previous_gain: 220.0 per tacts: 136 duration 0 days 00:40:36.062379\n","WRITTEN\n","opt# 5\n","random trial\n","scores for optimizers augmented [-77.28279261 328.89556758 771.7328284    2.28060186   4.99338927\n","   2.12338166   2.09204098   1.48693462 220.63599943]\n","chosen rel_coord_default previous_result: 220.0 per tacts: 136\n","score_new 533.3333333333334 score_prev 420.0 gained 113.33333333333337\n","score_new 400.0 score_prev 533.3333333333334 gained -133.33333333333337\n","undo\n","score_new 396.6666666666667 score_prev 533.3333333333334 gained -136.66666666666669\n","undo\n","score_new 586.6666666666666 score_prev 533.3333333333334 gained 53.33333333333326\n","score_new 666.6666666666666 score_prev 586.6666666666666 gained 80.0\n","score_new 520.0 score_prev 666.6666666666666 gained -146.66666666666663\n","undo\n","score_new 653.3333333333334 score_prev 666.6666666666666 gained -13.333333333333258\n","undo\n","score_new 506.6666666666667 score_prev 666.6666666666666 gained -159.99999999999994\n","undo\n","score_new 373.3333333333333 score_prev 666.6666666666666 gained -293.3333333333333\n","undo\n","score_new 376.6666666666667 score_prev 666.6666666666666 gained -289.99999999999994\n","undo\n","score_new 816.6666666666666 score_prev 666.6666666666666 gained 150.0\n","score_new 476.6666666666667 score_prev 816.6666666666666 gained -339.99999999999994\n","undo\n","score_new 416.6666666666667 score_prev 816.6666666666666 gained -399.99999999999994\n","undo\n","score_new 576.6666666666666 score_prev 816.6666666666666 gained -240.0\n","undo\n","score_new 353.3333333333333 score_prev 816.6666666666666 gained -463.3333333333333\n","undo\n","score_new 316.6666666666667 score_prev 816.6666666666666 gained -499.99999999999994\n","undo\n","score_new 1370.0 score_prev 816.6666666666666 gained 553.3333333333334\n","score_new 450.0 score_prev 1370.0 gained -920.0\n","undo\n","score_new 563.3333333333334 score_prev 1370.0 gained -806.6666666666666\n","undo\n","score_new 623.3333333333334 score_prev 1370.0 gained -746.6666666666666\n","undo\n","score_new 540.0 score_prev 1370.0 gained -830.0\n","undo\n","score_new 583.3333333333334 score_prev 1370.0 gained -786.6666666666666\n","undo\n","score_new 376.6666666666667 score_prev 1370.0 gained -993.3333333333333\n","undo\n","score_new 440.0 score_prev 1370.0 gained -930.0\n","undo\n","score_new 403.3333333333333 score_prev 1370.0 gained -966.6666666666667\n","undo\n","result rel_coord_default previous_gain: 220.0 per tacts: 136 duration 0 days 00:38:53.872553\n","WRITTEN\n","opt# 6\n","scores for optimizers augmented [-8.00450000e+01  3.26644167e+02  7.99975000e+02  1.65200000e+00\n","  2.22666667e+00 -4.20000000e-02 -7.50000000e-02  6.66666667e-02\n","  2.19932000e+02]\n","chosen rel_coord_default previous_result: 220.0 per tacts: 136\n","score_new 533.3333333333334 score_prev 513.3333333333334 gained 20.0\n","score_new 386.6666666666667 score_prev 533.3333333333334 gained -146.66666666666669\n","undo\n","score_new 563.3333333333334 score_prev 533.3333333333334 gained 30.0\n","score_new 503.3333333333333 score_prev 563.3333333333334 gained -60.00000000000006\n","undo\n","score_new 393.3333333333333 score_prev 563.3333333333334 gained -170.00000000000006\n","undo\n","score_new 450.0 score_prev 563.3333333333334 gained -113.33333333333337\n","undo\n","score_new 480.0 score_prev 563.3333333333334 gained -83.33333333333337\n","undo\n","score_new 636.6666666666666 score_prev 563.3333333333334 gained 73.33333333333326\n","score_new 423.3333333333333 score_prev 636.6666666666666 gained -213.33333333333331\n","undo\n","score_new 566.6666666666666 score_prev 636.6666666666666 gained -70.0\n","undo\n","score_new 580.0 score_prev 636.6666666666666 gained -56.66666666666663\n","undo\n","score_new 503.3333333333333 score_prev 636.6666666666666 gained -133.33333333333331\n","undo\n","score_new 510.0 score_prev 636.6666666666666 gained -126.66666666666663\n","undo\n","score_new 433.3333333333333 score_prev 636.6666666666666 gained -203.33333333333331\n","undo\n","score_new 453.3333333333333 score_prev 636.6666666666666 gained -183.33333333333331\n","undo\n","score_new 530.0 score_prev 636.6666666666666 gained -106.66666666666663\n","undo\n","score_new 846.6666666666666 score_prev 636.6666666666666 gained 210.0\n","score_new 463.3333333333333 score_prev 846.6666666666666 gained -383.3333333333333\n","undo\n","score_new 536.6666666666666 score_prev 846.6666666666666 gained -310.0\n","undo\n","score_new 500.0 score_prev 846.6666666666666 gained -346.66666666666663\n","undo\n","score_new 733.3333333333334 score_prev 846.6666666666666 gained -113.33333333333326\n","undo\n","score_new 630.0 score_prev 846.6666666666666 gained -216.66666666666663\n","undo\n"]}],"source":["\n","opt.function(opt.best_genoms[-1])\n","\n","for i in range(1000):\n","    print('opt#',i)\n","    opt.optimize()\n","    with open('genoms/best_genom_pacman.pkl', 'wb') as f:\n","        pickle.dump(opt.best_genoms,f,protocol=pickle.HIGHEST_PROTOCOL)\n","        print('WRITTEN')"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"LBhHJSL-ctuu"},"outputs":[{"name":"stdout","output_type":"stream","text":["q= 366.6666666666667\n"]}],"source":["with open('genoms/genom2.pkl', 'rb') as f:\n","    genom = pickle.load(f)#[-1]\n","q=multy_test(genom,draw=True)\n","print('q=',q)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"rquJJEbVcfgz"},"outputs":[],"source":["video[0].save(\n","    './out_videos/seaquest_pacman.gif',\n","    save_all=True,\n","    append_images=video[1:], \n","    optimize=True,\n","    duration=100,\n","    loop=0\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NolxDC4bdi7r"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP1/6tnER+ipw9TdwDyZ+sz","collapsed_sections":[],"mount_file_id":"1LelKGSZ7B8o8qafqCX4oFBtzHByVJ9FI","name":"atari_experiment2.ipynb","private_outputs":true,"provenance":[]},"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
