Это тулбокс для нейроэволюции, то есть поиска в пространстве стратегий. Тулбокс решает задачи построения оптимальной стратегии в тестовой среде. Например, такой средой может быть симулятор физики, где есть ракета, для неё задана некоторая цель, и задача - попасть ракетой как можно ближе к цели. Другой пример - игры Атари.

При нейроэволюционном подходе стратегия (наведения ракеты или выигрывания в Пакмена) записана некоей нейросетью. Причём можно взять все веса этой сети, записать их подряд и получится вектор - геном.

tasks.py
Одиночный тест (метод test из tasks.dymanic_test) - это однократный прогон агента в тестовой среде, например, в той среде про ракету. Тест получает на вход геном, а на выходе выдаёт число заработанных очков, оценку стратегии. Множественный тест (multy_test из tasks.dymanic_test) запускает тестовую среду несколько раз, с разными random seed.  Полный тест (full_test из tasks.dymanic_test) запускает множественный тест для некоторого списка сред. Список сред лежит в переменной list_envs в методе full_test.

optimizer.py
Оптимизатор подбирает такие веса нейросети, при которых full_test будет давать максимальный результат. Это подбор происходит посредством нескольких оптимизирующих алгоритмов - на данный момент это генетические алгоритмы с разными настройками и вариации градиентного спуска, но список расширяемый. Оптимизатор находится в файле optimize. Список optimizer_list в классе optimizer - это список доступных к запуску оптимизаторов, их код можно найти по названию. Каждый оптимизатор из списка применяется однократно, по итогам у него создаётся рейтинг (насколько сильный прирост дал, сколько времени потратил). Затем применяются те оптимизаторы, у которых рейтинг максимальный, причём рейтинг пересчитывается после каждого применения. Несколько оптимизаторов сделано потому, что нейроэволюция склонна к застреванию в локальных оптимумах, но разные оптимизаторы застревают в разных оптимумах.

nnet.py
В файле nnet находится нейросетевая библиотека, базирующаяся на numpy. Библиотека адаптирована под нейроэволюцию: есть методы assemble и disassemble, чтобы собрать сеть из генома или разобрать сеть в геном. С обратным распространением ошибки и с GPU несовместима.

neural_tape_controller.py
В этом файле находится контроллер, та самая запись стратегии. В идеале контроллер должен быть Тьюринг-полной нейросетью, то есть такой, которая может эмулировать любой компьютер. Это реализуется слоями 'turing_read', 'turing_move', 'turing_write', дающими доступ к тьюринговской ленте памяти. Слои modulator, modulator_inertial и modulable позволяют нейросети менять веса в процессе исполнения. Это экспериментальная функциональность, она может вести к нестабильности, но в ряде случаев ускоряет обучение. Остальные слои типичны для обычных нейросетей, и способ их применения показан при инициализации контроллера. Кроме того, в контроллере есть переменная tacts. Это количество циклов, которые отрабатывает нейросеть, прежде чем выдать решение.

Самый простой пример "на попробовать" - это aa_gun_experiment. Симуляция стрельбы из пушки по самолётам. fit_example - это обычное машинное обучение через нейроэволюцию (работает плохо, система сделана не для этого). atary_experiment - это эксперимент с играми Атари, я надеюсь, у вас он запустится.



