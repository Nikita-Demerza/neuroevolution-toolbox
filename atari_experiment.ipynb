{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"iV7GFD8QRQVe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: gym[atari] in /home/nikita/.local/lib/python3/site-packages (0.23.1)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /home/nikita/.local/lib/python3/site-packages (from gym[atari]) (2.0.0)\n","Requirement already satisfied: importlib-metadata>=4.10.0 in /home/nikita/.local/lib/python3/site-packages (from gym[atari]) (4.11.3)\n","Requirement already satisfied: gym-notices>=0.0.4 in /home/nikita/.local/lib/python3/site-packages (from gym[atari]) (0.0.6)\n","Requirement already satisfied: numpy>=1.18.0 in /home/nikita/.local/lib/python3/site-packages (from gym[atari]) (1.22.3)\n","Requirement already satisfied: ale-py~=0.7.4 in /home/nikita/.local/lib/python3/site-packages (from gym[atari]) (0.7.5)\n","Requirement already satisfied: importlib-resources in /home/nikita/.local/lib/python3/site-packages (from ale-py~=0.7.4->gym[atari]) (5.7.1)\n","Requirement already satisfied: zipp>=0.5 in /home/nikita/.local/lib/python3/site-packages (from importlib-metadata>=4.10.0->gym[atari]) (3.8.0)\n"]}],"source":["!pip3 install \"gym[atari]\"\n","import gym\n","import sys\n","from PIL import Image, ImageDraw\n","#sys.path.append('./drive/My Drive/Colab Notebooks/neuroevolution_toolbox/')\n","import numpy as np\n","import pandas as pd\n","import neural_tape_controller\n","#Положительные числа - положительные награды.\n","import tasks \n","import optimize\n","import pickle5 as pickle\n","root_dir = './'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lu9KS73QWPJH"},"outputs":[],"source":["# HIDE OUTPUT\n","!wget http://www.atarimania.com/roms/Roms.rar \n","!unrar x -o+ /content/Roms.rar >/dev/nul\n","!python -m atari_py.import_roms /content/ROMS >/dev/nul"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"gK_0udONWWcN"},"outputs":[{"name":"stdout","output_type":"stream","text":["Action Space: Discrete(4)\n","Observation Space: Box(0, 255, (210, 160, 3), uint8)\n","Max Episode Steps: 27000\n","Nondeterministic: False\n","Reward Range: (-inf, inf)\n","Reward Threshold: None\n"]}],"source":["def query_environment(name):\n","    env = gym.make(name)\n","    spec = gym.spec(name)\n","    print(f\"Action Space: {env.action_space}\")\n","    print(f\"Observation Space: {env.observation_space}\")\n","    print(f\"Max Episode Steps: {spec.max_episode_steps}\")\n","    print(f\"Nondeterministic: {spec.nondeterministic}\")\n","    print(f\"Reward Range: {env.reward_range}\")\n","    print(f\"Reward Threshold: {spec.reward_threshold}\")\n","query_environment(\"ALE/Breakout-v5\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"yHqp2lahT3dG"},"outputs":[],"source":["def encode_simple(X):\n","  #как сделать простое кодирование? Ну давай разобьём картинку двумя разными сетками и измерим яркость\n","  #на входе одиночная картинка\n","  y_lst = []\n","  sz = np.shape(X)\n","  count_squares = 7\n","  for i in range(count_squares):\n","    for j in range(count_squares):\n","      x = X[int(i*sz[0]/count_squares):int((i+1)*sz[0]/count_squares), int(j*sz[1]/count_squares):int((j+1)*sz[1]/count_squares)]\n","      y_lst.append(np.nanmean(x))\n","\n","  count_squares = 3\n","  for i in range(count_squares):\n","    for j in range(count_squares):\n","      x = X[int(i*sz[0]/count_squares):int((i+1)*sz[0]/count_squares), int(j*sz[1]/count_squares):int((j+1)*sz[1]/count_squares)]\n","      y_lst.append(np.nanmean(x))\n","\n","  count_squares = 2\n","  for i in range(count_squares):\n","    for j in range(count_squares):\n","      x = X[int(i*sz[0]/count_squares):int((i+1)*sz[0]/count_squares), int(j*sz[1]/count_squares):int((j+1)*sz[1]/count_squares)]\n","      y_lst.append(np.nanmean(x))\n","  #размер: 62\n","  return np.array(y_lst)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"_hxFWNWoOsmJ"},"outputs":[],"source":["n_actions = 4\n","embed_size = 62#это эмбеддинг картинки\n","nt = neural_tape_controller.nt_controller(input_size=embed_size,output_size=n_actions)\n","try:\n","    with open(root_dir+f'./genoms/best_genoms_breakout.pkl', 'rb') as f:\n","        genom = pickle.load(f)\n","        genom = genom[-1]\n","    print('loaded successfully')\n","except Exception:\n","    genom = nt.nn.disassemble_genom()"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"bXF5TTLgIheU"},"outputs":[],"source":["def test_atary(genom, draw=False,game_name=\"ALE/Breakout-v5\",seed=0):\n","  if draw:\n","    globals()['video'] = []\n","\n","  env = gym.make(game_name)\n","  env.reset()\n","  n_actions = env.action_space.n\n","  state_dim = env.observation_space.shape#здесь картинка\n","  #print('n_actions',n_actions,'state_dim',state_dim)\n","  #1/0\n","  state_dim = embed_size#это эмбеддинг картинки\n","  controller = neural_tape_controller.nt_controller(tacts=1,genom=np.array(genom),input_size=state_dim,output_size=n_actions) \n","  out_tape = np.zeros(30)\n","  reward_sum = 0\n","\n","  #seed=1\n","  np.random.seed(seed)\n","  env.seed(seed)\n","  for i in range(400):\n","      action = np.ravel(out_tape)\n","      action += np.random.rand(len(action))*np.std(action)*0.05#игра детерминистическая, иначе рандома не будет\n","      #print('action',int(np.argmax(action)),action)\n","      #исполнить env\n","      state, reward, done,_ = env.step(int(np.argmax(action)))\n","      t=pd.Timestamp.now()\n","      #state = encode_mobnet(np.array([state]))\n","      state = encode_simple(state)\n","      reward_sum += reward\n","      if np.shape(state)[0]>1:\n","          shp = np.shape(state)\n","          state = np.reshape(state,[1,shp[0]])\n","      out_tape = controller.act(state,reward,done)\n","      if draw:\n","        globals()['video'].append(Image.fromarray(env.render(\"rgb_array\")))\n","  return reward_sum"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"jn_DW2_xYhb_"},"outputs":[],"source":["def multy_test(genom):\n","  game_name = \"ALE/Breakout-v5\"\n","  #один энвайронмент, разные сиды\n","  q_arr = []\n","  for seed in range(3):\n","      q_arr.append(test_atary(genom, draw=False,game_name=game_name,seed=seed))\n","  return np.mean(q_arr) - 0.000000001*np.sum(genom**2)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"2bNLh6kmFzfY"},"outputs":[{"name":"stdout","output_type":"stream","text":["q= 0.0\n","CPU times: user 5.54 s, sys: 12.2 s, total: 17.8 s\n","Wall time: 20.5 s\n"]}],"source":["%%time\n","q=test_atary(genom,game_name=\"ALE/Breakout-v5\", draw=False)\n","print('q=',q)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"cGZxP_NhdC27"},"outputs":[{"name":"stdout","output_type":"stream","text":["q= -6.75390625e-09\n","CPU times: user 13.3 s, sys: 26.6 s, total: 39.9 s\n","Wall time: 53.4 s\n"]}],"source":["%%time\n","q=multy_test(genom)\n","print('q=',q)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Eja2m2P_ewzM"},"outputs":[{"name":"stdout","output_type":"stream","text":["q= 0.0\n","CPU times: user 3.92 s, sys: 6.93 s, total: 10.8 s\n","Wall time: 22.2 s\n"]}],"source":["%%time\n","q=test_atary(genom, draw=True,seed=0)\n","print('q=',q)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"hQ6UYltwAFag"},"outputs":[],"source":["video[0].save(\n","    root_dir+'./out_videos/breakout_neuroevol.gif',\n","    save_all=True,\n","    append_images=video[1:], \n","    optimize=True,\n","    duration=100,\n","    loop=0\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oN_h1Rg_2fQX"},"outputs":[],"source":["print(pd.Timestamp.now())"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"HzpNigFUTmIM"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n"]},{"name":"stderr","output_type":"stream","text":["/home/nikita/neuroevolution-toolbox/nnet.py:316: RuntimeWarning: overflow encountered in add\n","  self.belts[layer['belt_name']][:,:min_len] += in_data[:,:min_len]\n","/home/nikita/neuroevolution-toolbox/nnet.py:324: RuntimeWarning: overflow encountered in multiply\n","  k_add = np.arctan(k_amplif*self.belts[layer['belt_name']][:,:min_len]/threshold)*threshold\n"]},{"name":"stdout","output_type":"stream","text":["opt# 0\n","scores for optimizers augmented [1.e+10 1.e+10 1.e+10 1.e+10 1.e+10 1.e+10 1.e+10 1.e+10]\n","chosen evol_wide previous_result: nan per tacts: nan\n"]},{"name":"stderr","output_type":"stream","text":["/home/nikita/neuroevolution-toolbox/optimize.py:36: RuntimeWarning: Mean of empty slice\n","  mx.append(np.nanmean(self.history_gain[opt_name])-time_penalty*np.nanmean(self.history_time[opt_name]))\n","/home/nikita/.local/lib/python3/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n","  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"]},{"name":"stdout","output_type":"stream","text":["iteration 0 y= [5.66664426 4.33331092 2.99997765 2.99997756]\n","iteration 1 y= [5.66664426 4.33331092 3.66664425 3.33331091]\n","iteration 2 y= [5.66664426 4.33331092 4.33331091 3.66664425]\n","iteration 3 y= [5.66664426 4.33331092 4.33331091 3.66664425]\n","iteration final y= [5.66664426 5.33331093 5.33331092 4.33331092]\n","result evol_wide previous_gain: nan per tacts: nan duration 0 days 00:45:32.911093\n","WRITTEN\n","opt# 1\n","scores for optimizers augmented [-1.e-01  1.e+10  1.e+10  1.e+10  1.e+10  1.e+10  1.e+10  1.e+10]\n","chosen evol_mid_chaos previous_result: nan per tacts: nan\n","iteration 0 y= [5.66664426 4.33331095 2.66664432]\n","iteration 1 y= [5.66664426 5.6666441  4.33331095]\n","iteration final y= [6.99997728 6.99997727 5.66664426]\n","result evol_mid_chaos previous_gain: nan per tacts: nan duration 0 days 00:05:57.931042\n","WRITTEN\n","opt# 2\n","scores for optimizers augmented [-1.00000000e-01  1.31233301e+00  1.00000000e+10  1.00000000e+10\n","  1.00000000e+10  1.00000000e+10  1.00000000e+10  1.00000000e+10]\n","chosen gradient_wide_50 previous_result: nan per tacts: nan\n","score_new 6.999977277119492 score_prev 6.9999772772469155 gained -1.2742340516069817e-10\n","undo\n","score_new 6.999977277119492 score_prev 6.9999772772469155 gained -1.2742340516069817e-10\n","undo\n","score_new 6.999977277119492 score_prev 6.9999772772469155 gained -1.2742340516069817e-10\n","undo\n","score_new 6.999977277119492 score_prev 6.9999772772469155 gained -1.2742340516069817e-10\n","undo\n","result gradient_wide_50 previous_gain: nan per tacts: nan duration 0 days 00:05:19.819085\n","WRITTEN\n","opt# 3\n","scores for optimizers augmented [-1.00000000e-01  1.31233301e+00 -1.80000000e-02  1.00000000e+10\n","  1.00000000e+10  1.00000000e+10  1.00000000e+10  1.00000000e+10]\n","chosen rel_coord_default previous_result: nan per tacts: nan\n","score_new 6.999977277463694 score_prev 6.9999772772469155 gained 2.1677859507462927e-10\n","score_new 6.999977277463694 score_prev 6.999977277463694 gained 0.0\n","undo\n","score_new 6.999977277659337 score_prev 6.999977277463694 gained 1.9564261322102539e-10\n","score_new 6.999977277659337 score_prev 6.999977277659337 gained 0.0\n","undo\n","score_new 6.999977277835904 score_prev 6.999977277659337 gained 1.765672053011258e-10\n","score_new 6.999977277835904 score_prev 6.999977277835904 gained 0.0\n","undo\n","score_new 6.99997727766838 score_prev 6.999977277835904 gained -1.6752377263173912e-10\n","undo\n","score_new 5.333310611249935 score_prev 6.999977277835904 gained -1.6666666665859688\n","undo\n","score_new 6.999977277794789 score_prev 6.999977277835904 gained -4.11146672263385e-11\n","undo\n","score_new 5.333310611189603 score_prev 6.999977277835904 gained -1.666666666646301\n","undo\n","score_new 6.999977277825674 score_prev 6.999977277835904 gained -1.0230039038106042e-11\n","undo\n","score_new 5.3333106111743405 score_prev 6.999977277835904 gained -1.6666666666615635\n","undo\n","score_new 6.9999772778333496 score_prev 6.999977277835904 gained -2.55440113505756e-12\n","undo\n","score_new 5.333310611170514 score_prev 6.999977277835904 gained -1.6666666666653898\n","undo\n","score_new 6.999977277835266 score_prev 6.999977277835904 gained -6.377121053446899e-13\n","undo\n","score_new 5.333310611169557 score_prev 6.999977277835904 gained -1.6666666666663472\n","undo\n","score_new 6.999977277836064 score_prev 6.999977277835904 gained 1.5987211554602254e-13\n","score_new 6.999977277836064 score_prev 6.999977277836064 gained 0.0\n","undo\n","score_new 6.999977277835904 score_prev 6.999977277836064 gained -1.5987211554602254e-13\n","undo\n","score_new 6.999977277836144 score_prev 6.999977277836064 gained 7.993605777301127e-14\n","score_new 6.999977277836144 score_prev 6.999977277836144 gained 0.0\n","undo\n","score_new 6.999977277836064 score_prev 6.999977277836144 gained -7.993605777301127e-14\n","undo\n","score_new 6.999977277836184 score_prev 6.999977277836144 gained 3.9968028886505635e-14\n","score_new 6.999977277836184 score_prev 6.999977277836184 gained 0.0\n","undo\n","score_new 6.999977277836144 score_prev 6.999977277836184 gained -3.9968028886505635e-14\n","undo\n","result rel_coord_default previous_gain: nan per tacts: nan duration 0 days 00:11:55.179078\n","WRITTEN\n","opt# 4\n","scores for optimizers augmented [-1.00000000e-01  1.31233301e+00 -1.80000000e-02 -2.49999994e-02\n","  1.00000000e+10  1.00000000e+10  1.00000000e+10  1.00000000e+10]\n","chosen evol_soft previous_result: nan per tacts: nan\n","iteration 0 y= [6.99997728 6.99997728 6.99997728]\n","iteration 1 y= [6.99997728 6.99997728 6.99997728]\n","iteration 2 y= [6.99997728 6.99997728 6.99997728]\n","iteration 3 y= [6.99997728 6.99997728 6.99997728]\n","iteration 4 y= [6.99997728 6.99997728 6.99997728]\n","iteration final y= [6.99997728 6.99997728 6.99997728]\n","result evol_soft previous_gain: nan per tacts: nan duration 0 days 00:17:12.730973\n","WRITTEN\n","opt# 5\n","random trial\n","scores for optimizers augmented [1.20710689e-01 3.85196655e+00 5.42898627e-01 2.67807078e+00\n"," 4.42526342e-01 1.00000000e+10 1.00000000e+10 1.00000000e+10]\n","chosen gradient_long_adaptive previous_result: nan per tacts: nan\n","score_new 6.999977278022164 score_prev 6.999977278022164 gained 0.0\n","undo\n","score_new 6.999977278022164 score_prev 6.999977278022164 gained 0.0\n","undo\n","score_new 6.999977278022164 score_prev 6.999977278022164 gained 0.0\n","undo\n","score_new 6.999977278022164 score_prev 6.999977278022164 gained 0.0\n","undo\n","score_new 6.999977278022164 score_prev 6.999977278022164 gained 0.0\n","undo\n","score_new 6.999977278022164 score_prev 6.999977278022164 gained 0.0\n","undo\n","score_new 6.999977278022164 score_prev 6.999977278022164 gained 0.0\n","undo\n","score_new 6.999977278022164 score_prev 6.999977278022164 gained 0.0\n","undo\n","score_new 6.999977278022164 score_prev 6.999977278022164 gained 0.0\n","undo\n","score_new 6.999977278022164 score_prev 6.999977278022164 gained 0.0\n","undo\n","score_new 6.999977278022164 score_prev 6.999977278022164 gained 0.0\n","undo\n","score_new 6.999977278022164 score_prev 6.999977278022164 gained 0.0\n","undo\n","score_new 6.999977278022164 score_prev 6.999977278022164 gained 0.0\n","undo\n","score_new 6.999977278022164 score_prev 6.999977278022164 gained 0.0\n","undo\n","score_new 6.999977278022164 score_prev 6.999977278022164 gained 0.0\n","undo\n","result gradient_long_adaptive previous_gain: 0.0 per tacts: 150 duration 0 days 00:21:02.196347\n","WRITTEN\n","opt# 6\n","scores for optimizers augmented [-1.00000000e-01  1.31233301e+00 -1.80000000e-02 -2.49999994e-02\n"," -4.79999998e-02  1.00000000e+10  1.00000000e+10 -7.50000000e-02]\n","chosen gradient_long_adaptive_inertial previous_result: 0.0 per tacts: 150\n","score_new 6.999977278022165 score_prev 6.999977278022164 gained 8.881784197001252e-16\n","score_new 6.999977278022166 score_prev 6.999977278022165 gained 8.881784197001252e-16\n","score_new 6.9999772780221665 score_prev 6.999977278022166 gained 8.881784197001252e-16\n","score_new 6.999977278022168 score_prev 6.9999772780221665 gained 1.7763568394002505e-15\n","score_new 6.999977278022171 score_prev 6.999977278022168 gained 2.6645352591003757e-15\n","score_new 6.999977278022175 score_prev 6.999977278022171 gained 4.440892098500626e-15\n","score_new 6.999977278022182 score_prev 6.999977278022175 gained 6.217248937900877e-15\n","score_new 6.9999772780221905 score_prev 6.999977278022182 gained 8.881784197001252e-15\n","score_new 6.999977278022205 score_prev 6.9999772780221905 gained 1.4210854715202004e-14\n","score_new 6.999977278022225 score_prev 6.999977278022205 gained 2.042810365310288e-14\n","score_new 6.999977278022257 score_prev 6.999977278022225 gained 3.197442310920451e-14\n","score_new 6.999977278022303 score_prev 6.999977278022257 gained 4.618527782440651e-14\n","score_new 6.9999772780223735 score_prev 6.999977278022303 gained 7.016609515630989e-14\n","score_new 6.9999772780224765 score_prev 6.9999772780223735 gained 1.0302869668521453e-13\n","score_new 6.999977278022631 score_prev 6.9999772780224765 gained 1.545430450278218e-13\n","score_new 6.9999772780228575 score_prev 6.999977278022631 gained 2.2648549702353193e-13\n","score_new 6.999977278023188 score_prev 6.9999772780228575 gained 3.304023721284466e-13\n","score_new 6.999977278023664 score_prev 6.999977278023188 gained 4.760636329592671e-13\n","score_new 6.999977278024332 score_prev 6.999977278023664 gained 6.679101716144942e-13\n","score_new 6.999977278025231 score_prev 6.999977278024332 gained 8.988365607365267e-13\n","result gradient_long_adaptive_inertial previous_gain: 0.0 per tacts: 150 duration 0 days 00:09:56.861274\n","WRITTEN\n","opt# 7\n","scores for optimizers augmented [-1.00000000e-01  1.31233301e+00 -1.80000000e-02 -2.49999994e-02\n"," -4.79999998e-02 -4.00000000e-02  1.00000000e+10 -7.50000000e-02]\n","chosen gradient_slow_20 previous_result: 0.0 per tacts: 150\n","score_new 6.999977278025231 score_prev 6.999977278025231 gained 0.0\n","undo\n","score_new 6.999977278025231 score_prev 6.999977278025231 gained 0.0\n","undo\n","score_new 6.999977278025231 score_prev 6.999977278025231 gained 0.0\n","undo\n","score_new 6.999977278025231 score_prev 6.999977278025231 gained 0.0\n","undo\n","result gradient_slow_20 previous_gain: 0.0 per tacts: 150 duration 0 days 00:11:04.569314\n","WRITTEN\n","opt# 8\n","scores for optimizers augmented [-0.1         1.31233301 -0.018      -0.025      -0.048      -0.04\n"," -0.042      -0.075     ]\n","chosen evol_mid_chaos previous_result: 0.0 per tacts: 150\n","iteration 0 y= [6.99997728 6.99997728 6.99997728]\n","iteration 1 y= [6.99997728 6.99997728 6.99997728]\n","iteration final y= [8.33331052 6.99997728 6.99997728]\n","result evol_mid_chaos previous_gain: 0.0 per tacts: 150 duration 0 days 00:08:31.730808\n","WRITTEN\n","opt# 9\n","scores for optimizers augmented [-0.1         1.31233313 -0.018      -0.025      -0.048      -0.04\n"," -0.042      -0.075     ]\n","chosen evol_mid_chaos previous_result: 0.0 per tacts: 150\n","iteration 0 y= [8.33331052 6.99997708 5.66664375]\n","iteration 1 y= [8.33331052 6.99997708 6.99997692]\n","iteration final y= [8.33331052 6.99997708 6.99997692]\n","result evol_mid_chaos previous_gain: 0.0 per tacts: 150 duration 0 days 00:10:28.904743\n","WRITTEN\n","opt# 10\n","scores for optimizers augmented [-0.1         0.86788875 -0.018      -0.025      -0.048      -0.04\n"," -0.042      -0.075     ]\n","chosen evol_mid_chaos previous_result: 0.0 per tacts: 150\n","iteration 0 y= [8.33331052 6.99997691 6.99997691]\n","iteration 1 y= [8.33331052 6.99997691 6.99997691]\n","iteration final y= [8.33331052 8.33331009 6.99997691]\n","result evol_mid_chaos previous_gain: 0.0 per tacts: 150 duration 0 days 00:09:29.810720\n","WRITTEN\n","opt# 11\n","scores for optimizers augmented [-0.1         0.42344441 -0.018      -0.025      -0.048      -0.04\n"," -0.042      -0.075     ]\n","chosen evol_mid_chaos previous_result: 0.0 per tacts: 150\n","iteration 0 y= [8.33331052 8.33331009 3.66664419]\n","iteration 1 y= [8.33331052 8.33331009 6.99997658]\n","iteration final y= [8.33331052 8.33331009 6.99997658]\n","result evol_mid_chaos previous_gain: 0.0 per tacts: 150 duration 0 days 00:08:42.289024\n","WRITTEN\n","opt# 12\n","scores for optimizers augmented [-0.1   -0.021 -0.018 -0.025 -0.048 -0.04  -0.042 -0.075]\n","chosen gradient_wide_50 previous_result: 0.0 per tacts: 150\n","score_new 4.999977181753206 score_prev 8.3333105151225 gained -3.3333333333692945\n","undo\n","score_new 4.999977181753206 score_prev 8.3333105151225 gained -3.3333333333692945\n","undo\n","score_new 4.999977181753206 score_prev 8.3333105151225 gained -3.3333333333692945\n","undo\n","score_new 4.999977181753206 score_prev 8.3333105151225 gained -3.3333333333692945\n","undo\n","result gradient_wide_50 previous_gain: 0.0 per tacts: 150 duration 0 days 00:10:15.700546\n","WRITTEN\n","opt# 13\n","scores for optimizers augmented [-0.1   -0.021 -0.018 -0.025 -0.048 -0.04  -0.042 -0.075]\n","chosen gradient_wide_50 previous_result: 0.0 per tacts: 150\n","score_new 4.999977181753206 score_prev 8.3333105151225 gained -3.3333333333692945\n","undo\n","score_new 4.999977181753206 score_prev 8.3333105151225 gained -3.3333333333692945\n","undo\n","score_new 4.999977181753206 score_prev 8.3333105151225 gained -3.3333333333692945\n","undo\n","score_new 4.999977181753206 score_prev 8.3333105151225 gained -3.3333333333692945\n","undo\n","result gradient_wide_50 previous_gain: 0.0 per tacts: 150 duration 0 days 00:10:36.209691\n","WRITTEN\n","opt# 14\n","scores for optimizers augmented [-0.1   -0.021 -0.018 -0.025 -0.048 -0.04  -0.042 -0.075]\n","chosen gradient_wide_50 previous_result: 0.0 per tacts: 150\n","score_new 4.999977181753206 score_prev 8.3333105151225 gained -3.3333333333692945\n","undo\n","score_new 4.999977181753206 score_prev 8.3333105151225 gained -3.3333333333692945\n","undo\n","score_new 4.999977181753206 score_prev 8.3333105151225 gained -3.3333333333692945\n","undo\n","score_new 4.999977181753206 score_prev 8.3333105151225 gained -3.3333333333692945\n","undo\n","result gradient_wide_50 previous_gain: 0.0 per tacts: 150 duration 0 days 00:11:54.500415\n","WRITTEN\n","opt# 15\n","scores for optimizers augmented [-0.1   -0.021 -0.018 -0.025 -0.048 -0.04  -0.042 -0.075]\n","chosen gradient_wide_50 previous_result: 0.0 per tacts: 150\n","score_new 4.999977181753206 score_prev 8.3333105151225 gained -3.3333333333692945\n","undo\n","score_new 4.999977181753206 score_prev 8.3333105151225 gained -3.3333333333692945\n","undo\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/nikita/neuroevolution-toolbox/atari_experiment.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nikita/neuroevolution-toolbox/atari_experiment.ipynb#ch0000012?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nikita/neuroevolution-toolbox/atari_experiment.ipynb#ch0000012?line=11'>12</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mopt#\u001b[39m\u001b[39m'\u001b[39m,i)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nikita/neuroevolution-toolbox/atari_experiment.ipynb#ch0000012?line=12'>13</a>\u001b[0m     opt\u001b[39m.\u001b[39;49moptimize()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nikita/neuroevolution-toolbox/atari_experiment.ipynb#ch0000012?line=13'>14</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(root_dir\u001b[39m+\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbest_genoms.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nikita/neuroevolution-toolbox/atari_experiment.ipynb#ch0000012?line=14'>15</a>\u001b[0m         pickle\u001b[39m.\u001b[39mdump(opt\u001b[39m.\u001b[39mbest_genoms,f,protocol\u001b[39m=\u001b[39mpickle\u001b[39m.\u001b[39mHIGHEST_PROTOCOL)\n","File \u001b[0;32m~/neuroevolution-toolbox/optimize.py:63\u001b[0m, in \u001b[0;36moptimizer.optimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///home/nikita/neuroevolution-toolbox/optimize.py?line=60'>61</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_wide()\n\u001b[1;32m     <a href='file:///home/nikita/neuroevolution-toolbox/optimize.py?line=61'>62</a>\u001b[0m \u001b[39melif\u001b[39;00m chosen_optimizer\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgradient_wide_50\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> <a href='file:///home/nikita/neuroevolution-toolbox/optimize.py?line=62'>63</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_wide_50()\n\u001b[1;32m     <a href='file:///home/nikita/neuroevolution-toolbox/optimize.py?line=63'>64</a>\u001b[0m \u001b[39melif\u001b[39;00m chosen_optimizer\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgradient_slow_20\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='file:///home/nikita/neuroevolution-toolbox/optimize.py?line=64'>65</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_slow_20()\n","File \u001b[0;32m~/neuroevolution-toolbox/optimize.py:253\u001b[0m, in \u001b[0;36moptimizer.gradient_wide_50\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/nikita/neuroevolution-toolbox/optimize.py?line=250'>251</a>\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m0.05\u001b[39m\n\u001b[1;32m    <a href='file:///home/nikita/neuroevolution-toolbox/optimize.py?line=251'>252</a>\u001b[0m adapt\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m--> <a href='file:///home/nikita/neuroevolution-toolbox/optimize.py?line=252'>253</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient(width,stripe,maxiter,step,opt_name,adapt)\n","File \u001b[0;32m~/neuroevolution-toolbox/optimize.py:182\u001b[0m, in \u001b[0;36moptimizer.gradient\u001b[0;34m(self, width, stripe, maxiter, step, opt_name, adapt, chance_retry)\u001b[0m\n\u001b[1;32m    <a href='file:///home/nikita/neuroevolution-toolbox/optimize.py?line=179'>180</a>\u001b[0m \u001b[39mif\u001b[39;00m n_jobs\u001b[39m!=\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///home/nikita/neuroevolution-toolbox/optimize.py?line=180'>181</a>\u001b[0m     pool \u001b[39m=\u001b[39m Pool(processes\u001b[39m=\u001b[39mn_jobs)\n\u001b[0;32m--> <a href='file:///home/nikita/neuroevolution-toolbox/optimize.py?line=181'>182</a>\u001b[0m     y_lst \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mmap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction, [x \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m genoms])\n\u001b[1;32m    <a href='file:///home/nikita/neuroevolution-toolbox/optimize.py?line=182'>183</a>\u001b[0m     pool\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    <a href='file:///home/nikita/neuroevolution-toolbox/optimize.py?line=183'>184</a>\u001b[0m     pool\u001b[39m.\u001b[39mjoin()\n","File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/multiprocessing/pool.py?line=358'>359</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/multiprocessing/pool.py?line=359'>360</a>\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/multiprocessing/pool.py?line=360'>361</a>\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/multiprocessing/pool.py?line=361'>362</a>\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/multiprocessing/pool.py?line=362'>363</a>\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/lib64/python3.9/multiprocessing/pool.py?line=363'>364</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n","File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/multiprocessing/pool.py?line=763'>764</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> <a href='file:///usr/lib64/python3.9/multiprocessing/pool.py?line=764'>765</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/multiprocessing/pool.py?line=765'>766</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/multiprocessing/pool.py?line=766'>767</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n","File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/multiprocessing/pool.py?line=760'>761</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> <a href='file:///usr/lib64/python3.9/multiprocessing/pool.py?line=761'>762</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n","File \u001b[0;32m/usr/lib64/python3.9/threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/threading.py?line=571'>572</a>\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/threading.py?line=572'>573</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> <a href='file:///usr/lib64/python3.9/threading.py?line=573'>574</a>\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/threading.py?line=574'>575</a>\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n","File \u001b[0;32m/usr/lib64/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/threading.py?line=309'>310</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/threading.py?line=310'>311</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/lib64/python3.9/threading.py?line=311'>312</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/threading.py?line=312'>313</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib64/python3.9/threading.py?line=313'>314</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["print(1)\n","opt = optimize.optimizer(multy_test, genom_size=len(genom),parallel_cores=12)\n","try:\n","    with open(root_dir+f'best_genoms.pkl', 'rb') as f:\n","        opt.best_genoms = pickle.load(f)\n","    print('loaded successfully')\n","except Exception:\n","    pass\n","opt.function(opt.best_genoms[-1])\n","\n","for i in range(1000):\n","    print('opt#',i)\n","    opt.optimize()\n","    with open(root_dir+f'best_genoms.pkl', 'wb') as f:\n","        pickle.dump(opt.best_genoms,f,protocol=pickle.HIGHEST_PROTOCOL)\n","        print('WRITTEN')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qkGXbZVGgGVe"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN48uBUFnEbwUj2tWuWP5NH","collapsed_sections":[],"mount_file_id":"1E-HZlThJ8gTCVaj_9q52d5ZOW09pem_G","name":"atari_experiment.ipynb","private_outputs":true,"provenance":[]},"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
